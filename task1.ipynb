{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = pd.read_csv(\"MALE.csv\", header=0, index_col=None)\n",
    "female = pd.read_csv(\"FEMALE.csv\", header=0, index_col=None)\n",
    "mix = pd.read_csv(\"MIXED.csv\", header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    test_data = df.sample(n=100, random_state=0)\n",
    "    df = df.drop(test_data.index)\n",
    "    develop_data = df.sample(n=100, random_state=0)\n",
    "    train_data = df.drop(develop_data.index)\n",
    "    return train_data, develop_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_train, male_develop, male_test = split_data(male)\n",
    "female_train, female_develop, female_test = split_data(female)\n",
    "mix_train, mix_develop, mix_test = split_data(mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test, X_target, y_target):\n",
    "    #X_train, X_test, X_target = normalize(X_train), normalize(X_test), normalize(X_target)\n",
    "    #X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "\n",
    "    lr = LinearRegression(n_jobs=-1, normalize=True)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"score of Linear Regression:\", lr.score(X_test, y_test))\n",
    "    y_pred = lr.predict(X_target).round(0).astype(int)\n",
    "    print('Mean Squared Error for Linear Regression:', metrics.mean_squared_error(y_target, y_pred))  \n",
    "    print(\"accuracy score for Linear Regression:\", metrics.accuracy_score(y_target, y_pred))\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=100, solver='sgd', learning_rate='constant', activation='tanh',)\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(50,50,50), (50,100,50), (100, 200, 100), (50, 300, 100)],\n",
    "        'alpha': [0.0005, 0.0025, 0.001, 0.05],\n",
    "    }\n",
    "    #MLP with GridSearch\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Best paramete set\n",
    "    print('Best parameters found:\\n', clf.best_params_) \n",
    "    '''\n",
    "    # All results\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    #mlp.fit(X_train, y_train)\n",
    "    '''    \n",
    "    print(\"score of MLP:\", clf.score(X_test, y_test))\n",
    "    y_pred = clf.predict(X_target).round(0).astype(int)\n",
    "    print('Mean Squared Error for MLP:', metrics.mean_squared_error(y_target, y_pred))  \n",
    "    print(\"accuracy score for MLP:\", metrics.accuracy_score(y_target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SRCONLY: target is female\nscore of Linear Regression: 0.07989055357717878\nMean Squared Error for Linear Regression: 161.03\naccuracy score for Linear Regression: 0.05\nBest parameters found:\n {'alpha': 0.05, 'hidden_layer_sizes': (100, 200, 100)}\nscore of MLP: 0.055\nMean Squared Error for MLP: 242.81\naccuracy score for MLP: 0.01\n"
    }
   ],
   "source": [
    "'''\n",
    "SRCONLY:\n",
    "The SRCONLY baseline ignores the target data and\n",
    "trains a single model, only on the source data.\n",
    "\n",
    "source: male+mix\n",
    "target: female\n",
    "'''\n",
    "print(\"SRCONLY: target is female\")\n",
    "source_train = pd.concat([male_train, mix_train])\n",
    "source_develop = pd.concat([male_develop, mix_develop])\n",
    "target = female_test\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "model(X_train, y_train, X_test, y_test, X_target, y_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TGTONLY: target is female\nscore of Linear Regression: -0.11374860922435559\nMean Squared Error for Linear Regression: 146.89\naccuracy score for Linear Regression: 0.02\nBest parameters found:\n {'alpha': 0.0005, 'hidden_layer_sizes': (100, 200, 100)}\nscore of MLP: 0.02\nMean Squared Error for MLP: 161.35\naccuracy score for MLP: 0.14\n"
    }
   ],
   "source": [
    "'''\n",
    "TGTONLY:\n",
    "The TGTONLY baseline trains a single model only\n",
    "on the target data.\n",
    "\n",
    "source: female\n",
    "target: female\n",
    "'''\n",
    "print(\"TGTONLY: target is female\")\n",
    "source_train = female_test \n",
    "source_develop = female_develop\n",
    "target = female_test\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "model(X_train, y_train, X_test, y_test, X_target, y_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ALL: target is female\nscore of Linear Regression: 0.07280278281780084\nMean Squared Error for Linear Regression: 160.57\naccuracy score for Linear Regression: 0.05\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-34ca85a1ec85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Exam Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Exam Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mALL_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL_MLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-12d2357684ba>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, y_train, X_test, y_test, X_target, y_target)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#MLP with GridSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Best paramete set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters found:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "ALL:\n",
    "The ALL baseline simply trains a standard learning\n",
    "algorithm on the union of the two datasets\n",
    "\n",
    "source: male+female+mix\n",
    "target: female\n",
    "'''\n",
    "print(\"ALL: target is female\")\n",
    "source_train = pd.concat([male_train, female_test, mix_train])\n",
    "source_develop = pd.concat([male_develop, female_develop, mix_develop])\n",
    "target = female_test\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target,y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    " \n",
    "model(X_train, y_train, X_test, y_test, X_target, y_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WEIGHTED: target is female\nscore of Linear Regression: 0.07036395772482773\nMean Squared Error for Linear Regression: 165.71\naccuracy score for Linear Regression: 0.03\nBest parameters found:\n {'alpha': 0.05, 'hidden_layer_sizes': (100, 200, 100)}\nscore of MLP: 0.02\nMean Squared Error for MLP: 233.58\naccuracy score for MLP: 0.04\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True),\n GridSearchCV(cv=5, error_score=nan,\n              estimator=MLPClassifier(activation='tanh', alpha=0.0001,\n                                      batch_size='auto', beta_1=0.9,\n                                      beta_2=0.999, early_stopping=False,\n                                      epsilon=1e-08, hidden_layer_sizes=(100,),\n                                      learning_rate='constant',\n                                      learning_rate_init=0.001, max_fun=15000,\n                                      max_iter=100, momentum=0.9,\n                                      n_iter_no_change=10,\n                                      nesterovs_momentum=True, power_t=0.5,\n                                      random_state=None, shuffle=True,\n                                      solver='sgd', tol=0.0001,\n                                      validation_fraction=0.1, verbose=False,\n                                      warm_start=False),\n              iid='deprecated', n_jobs=-1,\n              param_grid={'alpha': [0.0005, 0.0025, 0.001, 0.05],\n                          'hidden_layer_sizes': [(50, 50, 50), (50, 100, 50),\n                                                 (100, 200, 100),\n                                                 (50, 300, 100)]},\n              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n              scoring=None, verbose=0))"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "'''\n",
    "WEIGHTED:\n",
    "For instance, if N = 10 x \u0002M, we may weight each example from the source domain by 0:1. \n",
    "The next baseline, WEIGHTED, is exactly this approach, with the weight chosen by cross-validation.\n",
    "\n",
    "source: male+female+mix\n",
    "target: female\n",
    "'''\n",
    "print(\"WEIGHTED: target is female\")\n",
    "orginal_n_samples = len(pd.concat([male_train, female_test, mix_train]))\n",
    "source_train = pd.concat([male_train, mix_train, female_test, female_test, female_test]).sample(n=orginal_n_samples, random_state=0)\n",
    "source_develop = pd.concat([male_develop, female_develop, mix_develop])\n",
    "target = female_test\n",
    "\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "model(X_train, y_train, X_test, y_test, X_target, y_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PRED: target is female Linear Regression\nscore of Linear Regression: 0.0293595878923838\nMean Squared Error for Linear Regression: 158.21\naccuracy score for Linear Regression: 0.01\nPRED: target is female MLP Classifier\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-4d4c50a7dfc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#MLP with GridSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;31m# Best paramete set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters found:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "PRED:\n",
    "using the output of the source classifier as a feature in the target classifier. \n",
    "Specifically, we first train a SRCONLY model. Then we run the SRCONLY model \n",
    "on the target data (training, development and test). We use the predictions \n",
    "made by the SRCONLY model as additional features and\n",
    "train a second model on the target data, augmented with this new feature.\n",
    "\n",
    "source: prdictions in SRCONLY + target data\n",
    "target: female\n",
    "'''\n",
    "print(\"PRED: prdictions in SRCONLY Linear Regression\")\n",
    "source_train = pd.concat([male_train, mix_train])\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "#X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "src_lr = LinearRegression(n_jobs=-1, normalize=True)\n",
    "src_lr.fit(X_train, y_train)\n",
    "\n",
    "#linear regression\n",
    "print(\"PRED: target is female Linear Regression\")\n",
    "source_train = female_train\n",
    "source_develop = female_develop\n",
    "target = female_test\n",
    "\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "X_train['srconly_feature'] = src_lr.predict(X_train).round(0).astype(int)\n",
    "X_test['srconly_feature'] = src_lr.predict(X_test).round(0).astype(int)\n",
    "X_target['srconly_feature'] = src_lr.predict(X_target).round(0).astype(int)\n",
    "\n",
    "#X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "lr = LinearRegression(n_jobs=-1, normalize=True)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"score of Linear Regression:\", lr.score(X_test, y_test))\n",
    "y_pred = lr.predict(X_target).round(0).astype(int)\n",
    "print('Mean Squared Error for Linear Regression:', metrics.mean_squared_error(y_target, y_pred))  \n",
    "print(\"accuracy score for Linear Regression:\", metrics.accuracy_score(y_target, y_pred))\n",
    "\n",
    "#mlp\n",
    "print(\"PRED: prdictions in SRCONLY MLP\")\n",
    "source_train = pd.concat([male_train, mix_train])\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "mlp = MLPClassifier(max_iter=100, solver='sgd', learning_rate='constant', activation='tanh',)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100, 200, 100), (50, 300, 100)],\n",
    "    'alpha': [0.0005, 0.0025, 0.001, 0.05],\n",
    "}\n",
    "scr_clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "scr_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"PRED: target is female MLP Classifier\")\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "X_test, y_test = source_develop.drop(['Exam Score'], axis=1), source_develop['Exam Score']\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "X_train['srconly_feature'] = scr_clf.predict(X_train).round(0).astype(int)\n",
    "X_test['srconly_feature'] = scr_clf.predict(X_test).round(0).astype(int)\n",
    "X_target['srconly_feature'] = scr_clf.predict(X_target).round(0).astype(int)\n",
    "\n",
    "#X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "mlp = MLPClassifier(max_iter=100, solver='sgd', learning_rate='constant', activation='tanh',)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100, 200, 100), (50, 300, 100)],\n",
    "    'alpha': [0.0005, 0.0025, 0.001, 0.05],\n",
    "}\n",
    "#MLP with GridSearch\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "# Best paramete set\n",
    "print('Best parameters found:\\n', clf.best_params_)  \n",
    "print(\"score of MLP:\", clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_target).round(0).astype(int)\n",
    "print('Mean Squared Error for MLP:', metrics.mean_squared_error(y_target, y_pred))  \n",
    "print(\"accuracy score for MLP:\", metrics.accuracy_score(y_target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LININT: prdictions in SRCONLY Linear Regression\nLININT: prdictions in TGTONLY Linear Regression\nweight is equal to 0.98\nMean Squared Error for linear regression: 146.89\naccuracy score for linear regression: 0.02\nweight is equal to 0\nMean Squared Error for MLP: 411.12\naccuracy score for MLP: 0.02\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LININT:\n",
    "linearly interpolate the predictions of the SRCONLY \n",
    "and the TGTONLY models. The interpolation parameter is\n",
    "adjusted based on target development data.\n",
    "\n",
    "source: prdictions in SRCONLY + prdictions in TGTONLY\n",
    "target: female\n",
    "\"\"\"\n",
    "target = female_test\n",
    "X_target, y_target = target.drop(['Exam Score'], axis=1), target['Exam Score']\n",
    "\n",
    "print(\"LININT: prdictions in SRCONLY Linear Regression\")\n",
    "source_train = pd.concat([male_train, mix_train])\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "#X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "src_lr = LinearRegression(n_jobs=-1, normalize=True)\n",
    "src_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"LININT: prdictions in TGTONLY Linear Regression\")\n",
    "source_train = female_test\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "#X_train, X_test, X_target = scale(X_train), scale(X_test), scale(X_target)\n",
    "tgt_lr = LinearRegression(n_jobs=-1, normalize=True)\n",
    "tgt_lr.fit(X_train, y_train)\n",
    "\n",
    "'''linear regression'''\n",
    "srconly_lr_y_pred = src_lr.predict(X_target).round(0).astype(int)\n",
    "tgtonly_lr_y_pred = tgt_lr.predict(X_target).round(0).astype(int)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"srconly\"] = srconly_lr_y_pred\n",
    "df[\"tgtonly\"] = tgtonly_lr_y_pred\n",
    "\n",
    "w , mse = 0, min(metrics.mean_squared_error(y_target, srconly_lr_y_pred), metrics.mean_squared_error(y_target, tgtonly_lr_y_pred)) \n",
    "#tuning the weight hyperparameter\n",
    "for i in range (1, 100):\n",
    "    new_w = i/100\n",
    "    new_linint = df[\"srconly\"] + new_w * (df[\"tgtonly\"] - df[\"srconly\"]) \n",
    "    #new_linint = df[\"srconly\"] * new_w + df[\"tgtonly\"] * (1 - new_w) # method 2 https://arxiv.org/pdf/1312.6204.pdf\n",
    "    new_mse = metrics.mean_squared_error(y_target, new_linint)\n",
    "    if new_mse < mse :\n",
    "        w , mse = new_w, new_mse\n",
    "\n",
    "print(\"weight is equal to\", w)\n",
    "df['pred'] = df[\"srconly\"] + w * (df[\"tgtonly\"] - df[\"srconly\"]) \n",
    "#linint = df[\"srconly\"] * w + df[\"tgtonly\"] * (1 - w)\n",
    "print('Mean Squared Error for linear regression:', metrics.mean_squared_error(y_target, df['pred'].round(0).astype(int)))\n",
    "print(\"accuracy score for linear regression:\", metrics.accuracy_score(y_target, df['pred'].round(0).astype(int)))\n",
    "\n",
    "'''MLP'''\n",
    "print(\"LININT: prdictions in SRCONLY MLP\")\n",
    "source_train = pd.concat([male_train, mix_train])\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "mlp = MLPClassifier(max_iter=100, solver='sgd', learning_rate='constant', activation='tanh',)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100, 200, 100), (50, 300, 100)],\n",
    "    'alpha': [0.0005, 0.0025, 0.001, 0.05],\n",
    "}\n",
    "scr_clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "scr_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"LININT: prdictions in TGTONLY MLP\")\n",
    "source_train = female_test\n",
    "X_train, y_train = source_train.drop(['Exam Score'], axis=1), source_train['Exam Score']\n",
    "mlp = MLPClassifier(max_iter=100, solver='sgd', learning_rate='constant', activation='tanh',)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100, 200, 100), (50, 300, 100)],\n",
    "    'alpha': [0.0005, 0.0025, 0.001, 0.05],\n",
    "}\n",
    "tgt_clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "tgt_clf.fit(X_train, y_train)\n",
    "\n",
    "srconly_mlp_y_pred = scr_clf.predict(X_target).round(0).astype(int)\n",
    "tgtonly_mlp_y_pred = tgt_clf.predict(X_target).round(0).astype(int)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"srconly\"] = srconly_mlp_y_pred\n",
    "df[\"tgtonly\"] = tgtonly_mlp_y_pred\n",
    "\n",
    "w , mse = 0, min(metrics.mean_squared_error(y_target, srconly_mlp_y_pred), metrics.mean_squared_error(y_target, tgtonly_mlp_y_pred)) \n",
    "#tuning the weight hyperparameter\n",
    "for i in range (1, 100):\n",
    "    new_w = i/100\n",
    "    new_linint = df[\"srconly\"] + new_w * (df[\"tgtonly\"] - df[\"srconly\"]) \n",
    "    #new_linint = df[\"srconly\"] * new_w + df[\"tgtonly\"] * (1 - new_w) # method 2 https://arxiv.org/pdf/1312.6204.pdf\n",
    "    new_mse = metrics.mean_squared_error(y_target, new_linint)\n",
    "    if new_mse < mse :\n",
    "        w , mse = new_w, new_mse\n",
    "\n",
    "print(\"weight is equal to\", w)\n",
    "df['pred'] = df[\"srconly\"] + w * (df[\"tgtonly\"] - df[\"srconly\"]) \n",
    "#linint = df[\"srconly\"] * w + df[\"tgtonly\"] * (1 - w)\n",
    "print('Mean Squared Error for MLP:', metrics.mean_squared_error(y_target, df['pred'].round(0).astype(int)))\n",
    "print(\"accuracy score for MLP:\", metrics.accuracy_score(y_target, df['pred'].round(0).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nhttp://users.umiacs.umd.edu/~hal/docs/daume07easyadapt.odp.pdf\\n\\nhttps://www.aclweb.org/anthology/N18-2076.pdf\\n\\nhttps://slideplayer.com/slide/10770963/\\n\\n\\nhttp://mlreference.com/feedforward-neural-network-sklearn\\n'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "'''\n",
    "http://users.umiacs.umd.edu/~hal/docs/daume07easyadapt.odp.pdf\n",
    "\n",
    "https://www.aclweb.org/anthology/N18-2076.pdf\n",
    "\n",
    "https://slideplayer.com/slide/10770963/\n",
    "\n",
    "\n",
    "http://mlreference.com/feedforward-neural-network-sklearn\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit302d15dce58f496582bcd70ccd75218f",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}